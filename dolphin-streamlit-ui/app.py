import streamlit as st
import os
import sys
import time
import json
import re
import openai
from dotenv import load_dotenv
from pathlib import Path
from datetime import datetime
import threading
import queue
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import tempfile
import logging
import traceback
import subprocess
import hashlib
import shutil
import re
from typing import Optional, Dict, Any, List, Tuple
import warnings
from streamlit_mic_recorder import mic_recorder

# å¿½ç•¥è­¦å‘Šä»¥ä¿æŒè¾“å‡ºæ¸…æ´
warnings.filterwarnings("ignore")

# é…ç½®ä¸­æ–‡å‹å¥½çš„æ—¥å¿—ç³»ç»Ÿ
class ChineseFormatter(logging.Formatter):
    """ä¸­æ–‡å‹å¥½çš„æ—¥å¿—æ ¼å¼åŒ–å™¨"""
    def format(self, record):
        # ç¡®ä¿æ‰€æœ‰æ—¥å¿—æ¶ˆæ¯éƒ½ä»¥ä¸­æ–‡è¾“å‡º
        if hasattr(record, 'msg') and record.msg:
            # å°†è‹±æ–‡é”™è¯¯ä¿¡æ¯è½¬æ¢ä¸ºä¸­æ–‡
            error_translations = {
                'Connection error': 'è¿æ¥é”™è¯¯',
                'Timeout error': 'è¶…æ—¶é”™è¯¯',
                'File not found': 'æ–‡ä»¶æœªæ‰¾åˆ°',
                'Permission denied': 'æƒé™è¢«æ‹’ç»',
                'Invalid format': 'æ ¼å¼æ— æ•ˆ',
                'Processing failed': 'å¤„ç†å¤±è´¥',
                'API error': 'APIé”™è¯¯',
                'Network error': 'ç½‘ç»œé”™è¯¯'
            }
            
            msg = str(record.msg)
            for en, zh in error_translations.items():
                msg = msg.replace(en, zh)
            record.msg = msg
        
        return super().format(record)

# é…ç½®æ—¥å¿—ç³»ç»Ÿ - ç›´æ¥è¾“å‡ºåˆ°å‘½ä»¤è¡Œ
def setup_logging():
    """è®¾ç½®ä¸­æ–‡å‹å¥½çš„æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    
    # è®¾ç½®ä¸­æ–‡å‹å¥½çš„æ ¼å¼
    formatter = ChineseFormatter(
        '%(asctime)s - [%(levelname)s] - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)
    return logger

logger = setup_logging()

# Add FFmpeg to PATH for pydub
ffmpeg_path = r'd:\zhuanlu\ffmpeg_portable'
if ffmpeg_path not in os.environ['PATH']:
    os.environ['PATH'] += os.pathsep + ffmpeg_path

sys.path.insert(0, r'd:\zhuanlu\Dolphin-main')
from dolphin.transcribe import load_model, transcribe, transcribe_long
from dolphin.constants import SPEECH_LENGTH
from dolphin.audio import load_audio
import pydub
from pydub import AudioSegment
from pydub.effects import normalize, high_pass_filter

# åŠ è½½OpenAI APIå¯†é’¥
load_dotenv()
openai.api_key = os.getenv('OPENAI_API_KEY')

# é¡µé¢é…ç½® - ä¸­æ–‡ä¼˜åŒ–
st.set_page_config(
    page_title="æ™ºèƒ½è¯­éŸ³è½¬å½•åŠ©æ‰‹ - ä¸­æ–‡ä¸“ä¸šç‰ˆ",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ä¸­æ–‡å‹å¥½çš„è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    /* å…¨å±€ä¸­æ–‡å­—ä½“ä¼˜åŒ– */
    .main {
        font-family: "Microsoft YaHei", "PingFang SC", "Hiragino Sans GB", "WenQuanYi Micro Hei", sans-serif;
    }
    
    /* æ ‡é¢˜æ ·å¼ä¼˜åŒ– */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        margin-bottom: 0.5rem;
        font-weight: 700;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .main-header p {
        font-size: 1.2rem;
        opacity: 0.9;
        margin: 0;
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸæ ·å¼ */
    .upload-area {
        border: 3px dashed #667eea;
        border-radius: 15px;
        padding: 3rem;
        text-align: center;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        margin: 2rem 0;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #764ba2;
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
    }
    
    /* æˆåŠŸæ¶ˆæ¯æ ·å¼ */
    .success-message {
        background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
        font-weight: 500;
    }
    
    /* é”™è¯¯æ¶ˆæ¯æ ·å¼ */
    .error-message {
        background: linear-gradient(135deg, #f44336 0%, #d32f2f 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
        font-weight: 500;
    }
    
    /* ä¿¡æ¯å¡ç‰‡æ ·å¼ */
    .feature-card {
        background: white;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        margin: 1rem 0;
        border-left: 5px solid #667eea;
    }
    
    /* æ–‡æœ¬åŒºåŸŸæ ·å¼ */
    .stTextArea textarea {
        font-family: "Microsoft YaHei", "PingFang SC", sans-serif;
        font-size: 16px;
        line-height: 1.6;
        border-radius: 10px;
        border: 2px solid #e0e0e0;
        transition: border-color 0.3s ease;
    }
    
    .stTextArea textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 10px rgba(102, 126, 234, 0.3);
    }
    
    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.3);
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤º */
    .file-info {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 4px solid #28a745;
    }
    
    .progress-container {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e0e0e0;
        margin: 1rem 0;
    }
    .export-button {
        background: #28a745;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        border: none;
        cursor: pointer;
        margin: 0.25rem;
    }
    .selectable-text {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #dee2e6;
        font-family: 'Courier New', monospace;
        line-height: 1.6;
        user-select: text;
        -webkit-user-select: text;
        -moz-user-select: text;
        -ms-user-select: text;
    }
    .api-section {
        background: #e3f2fd;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    
    /* ç»Ÿè®¡ä¿¡æ¯æ ·å¼ */
    .stats-container {
        display: flex;
        justify-content: space-around;
        background: white;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        margin: 1rem 0;
    }
    
    .stat-item {
        text-align: center;
    }
    
    .stat-number {
        font-size: 2rem;
        font-weight: bold;
        color: #667eea;
    }
    
    .stat-label {
        color: #666;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# å¤§æ–‡ä»¶é¢„å¤„ç†åŠŸèƒ½
class FilePreprocessor:
    """å¤§æ–‡ä»¶é¢„å¤„ç†å™¨ - ä¸“ä¸ºä¸­æ–‡éŸ³é¢‘ä¼˜åŒ–"""
    
    def __init__(self):
        self.temp_dir = Path("temp")
        self.temp_dir.mkdir(exist_ok=True)
        self.max_chunk_size = 25 * 1024 * 1024  # 25MB per chunk
        self.supported_formats = ['.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg', '.wma']
        
    def get_file_hash(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def check_file_format(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ"""
        file_ext = Path(file_path).suffix.lower()
        return file_ext in self.supported_formats
    
    def get_audio_info(self, file_path: str) -> Dict[str, Any]:
        """è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯"""
        try:
            from pydub import AudioSegment
            audio = AudioSegment.from_file(file_path)
            
            info = {
                'duration': len(audio) / 1000,  # ç§’
                'channels': audio.channels,
                'sample_rate': audio.frame_rate,
                'format': Path(file_path).suffix.lower(),
                'size': os.path.getsize(file_path),
                'bitrate': audio.frame_rate * audio.sample_width * 8 * audio.channels
            }
            
            logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯: æ—¶é•¿ {info['duration']:.1f}ç§’, é‡‡æ ·ç‡ {info['sample_rate']}Hz, å£°é“æ•° {info['channels']}")
            return info
            
        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def optimize_audio_for_chinese(self, file_path: str) -> str:
        """ä¸ºä¸­æ–‡è¯­éŸ³è¯†åˆ«ä¼˜åŒ–éŸ³é¢‘"""
        try:
            from pydub import AudioSegment
            from pydub.effects import normalize
            
            logger.info("å¼€å§‹ä¼˜åŒ–éŸ³é¢‘ä»¥æé«˜ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡...")
            
            # åŠ è½½éŸ³é¢‘
            audio = AudioSegment.from_file(file_path)
            
            # ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–å¤„ç†
            # 1. è½¬æ¢ä¸ºå•å£°é“ï¼ˆä¸­æ–‡è¯­éŸ³è¯†åˆ«é€šå¸¸åœ¨å•å£°é“ä¸‹æ•ˆæœæ›´å¥½ï¼‰
            if audio.channels > 1:
                audio = audio.set_channels(1)
                logger.info("å·²è½¬æ¢ä¸ºå•å£°é“")
            
            # 2. è®¾ç½®æœ€é€‚åˆä¸­æ–‡çš„é‡‡æ ·ç‡ (16kHz)
            if audio.frame_rate != 16000:
                audio = audio.set_frame_rate(16000)
                logger.info("å·²è®¾ç½®é‡‡æ ·ç‡ä¸º16kHzï¼ˆä¸­æ–‡è¯­éŸ³è¯†åˆ«æœ€ä½³ï¼‰")
            
            # 3. éŸ³é‡æ ‡å‡†åŒ–
            audio = normalize(audio)
            logger.info("å·²è¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–")
            
            # 4. é™å™ªå¤„ç†ï¼ˆç®€å•çš„é«˜é€šæ»¤æ³¢ï¼‰
            # ç§»é™¤ä½é¢‘å™ªéŸ³ï¼Œä¿ç•™ä¸­æ–‡è¯­éŸ³çš„ä¸»è¦é¢‘ç‡èŒƒå›´
            audio = audio.high_pass_filter(80)
            logger.info("å·²åº”ç”¨é«˜é€šæ»¤æ³¢å™¨å»é™¤ä½é¢‘å™ªéŸ³")
            
            # ä¿å­˜ä¼˜åŒ–åçš„æ–‡ä»¶
            optimized_path = str(self.temp_dir / f"optimized_{Path(file_path).name}")
            audio.export(optimized_path, format="wav")
            
            logger.info(f"éŸ³é¢‘ä¼˜åŒ–å®Œæˆï¼Œä¿å­˜è‡³: {optimized_path}")
            return optimized_path
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return file_path
    
    def split_large_file(self, file_path: str, chunk_duration: int = 300) -> List[str]:
        """åˆ†å‰²å¤§æ–‡ä»¶ä¸ºå°å—ï¼ˆé»˜è®¤5åˆ†é’Ÿä¸€å—ï¼‰"""
        try:
            from pydub import AudioSegment
            
            audio = AudioSegment.from_file(file_path)
            duration_ms = len(audio)
            chunk_duration_ms = chunk_duration * 1000
            
            if duration_ms <= chunk_duration_ms:
                return [file_path]
            
            logger.info(f"æ–‡ä»¶è¾ƒå¤§ï¼ˆ{duration_ms/1000:.1f}ç§’ï¼‰ï¼Œå¼€å§‹åˆ†å‰²ä¸º{chunk_duration}ç§’çš„ç‰‡æ®µ...")
            
            chunks = []
            chunk_count = 0
            
            for start_ms in range(0, duration_ms, chunk_duration_ms):
                end_ms = min(start_ms + chunk_duration_ms, duration_ms)
                chunk = audio[start_ms:end_ms]
                
                chunk_filename = f"chunk_{chunk_count:03d}_{Path(file_path).stem}.wav"
                chunk_path = str(self.temp_dir / chunk_filename)
                
                chunk.export(chunk_path, format="wav")
                chunks.append(chunk_path)
                chunk_count += 1
                
                logger.info(f"å·²åˆ›å»ºç‰‡æ®µ {chunk_count}: {start_ms/1000:.1f}s - {end_ms/1000:.1f}s")
            
            logger.info(f"æ–‡ä»¶åˆ†å‰²å®Œæˆï¼Œå…±åˆ›å»º {len(chunks)} ä¸ªç‰‡æ®µ")
            return chunks
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶åˆ†å‰²å¤±è´¥: {str(e)}")
            return [file_path]
    
    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            for file_path in self.temp_dir.glob("*"):
                if file_path.is_file():
                    file_path.unlink()
            logger.info("ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

# åˆå§‹åŒ–æ–‡ä»¶é¢„å¤„ç†å™¨
preprocessor = FilePreprocessor()

# ä¸»æ ‡é¢˜ - ä¸­æ–‡ä¸“ä¸šç‰ˆ
st.markdown("""
<div class="main-header">
    <h1>ğŸ™ï¸ æ™ºèƒ½è¯­éŸ³è½¬å½•åŠ©æ‰‹</h1>
    <p>ä¸“ä¸šä¸­æ–‡è¯­éŸ³è¯†åˆ« | æ”¯æŒå¤§æ–‡ä»¶å¤„ç† | AIæ™ºèƒ½ä¼˜åŒ–</p>
</div>
""", unsafe_allow_html=True)

# ä¾§è¾¹æ é…ç½® - ä¸­æ–‡ä¼˜åŒ–
with st.sidebar:
    st.markdown("### ğŸ”§ è½¬å½•é…ç½®")
    # æ·»åŠ æ–°ä¼˜åŒ–é€‰é¡¹
    enable_ai_enhance = st.checkbox("å¯ç”¨AIå¢å¼ºè½¬å½•", value=True, help="ä½¿ç”¨AIä¼˜åŒ–è½¬å½•ç»“æœ")
    
    # Whisperæ¨¡å‹é€‰æ‹©
    model_name = st.selectbox(
        "é€‰æ‹©Whisperæ¨¡å‹",
        options=["small", "base", "medium", "large"],
        index=1,
        help="æ›´å¤§çš„æ¨¡å‹å‡†ç¡®ç‡æ›´é«˜ï¼Œä½†å¤„ç†é€Ÿåº¦è¾ƒæ…¢"
    )
    
    # è®¾å¤‡é€‰æ‹©
    device = st.selectbox(
        "è®¡ç®—è®¾å¤‡",
        options=["cpu", "cuda"],
        index=0,
        help="å¦‚æœæœ‰NVIDIA GPUï¼Œé€‰æ‹©cudaå¯ä»¥æ˜¾è‘—æå‡é€Ÿåº¦"
    )
    
    # è¯­è¨€è®¾ç½® - é»˜è®¤ä¸­æ–‡
    language = st.selectbox(
        "è¯†åˆ«è¯­è¨€",
        options=["zh", "auto", "en"],
        index=0,  # é»˜è®¤ä¸­æ–‡
        format_func=lambda x: {
            "zh": "ä¸­æ–‡ï¼ˆæ¨èï¼‰",
            "auto": "è‡ªåŠ¨æ£€æµ‹",
            "en": "è‹±æ–‡"
        }[x],
        help="å»ºè®®é€‰æ‹©ä¸­æ–‡ä»¥è·å¾—æœ€ä½³è¯†åˆ«æ•ˆæœ"
    )
    
    st.markdown("---")
    
    # å¤§æ–‡ä»¶å¤„ç†é€‰é¡¹
    st.markdown("### ğŸ“ å¤§æ–‡ä»¶å¤„ç†")
    
    enable_preprocessing = st.checkbox(
        "å¯ç”¨éŸ³é¢‘é¢„å¤„ç†",
        value=True,
        help="ä¸ºä¸­æ–‡è¯­éŸ³è¯†åˆ«ä¼˜åŒ–éŸ³é¢‘è´¨é‡"
    )
    
    auto_split = st.checkbox(
        "è‡ªåŠ¨åˆ†å‰²å¤§æ–‡ä»¶",
        value=True,
        help="å°†é•¿éŸ³é¢‘åˆ†å‰²ä¸ºå°æ®µä»¥æé«˜å¤„ç†æ•ˆç‡"
    )
    
    chunk_duration = st.slider(
        "åˆ†å‰²æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰",
        min_value=1,
        max_value=10,
        value=5,
        help="æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µçš„æ—¶é•¿"
    )
    
    st.markdown("---")
    
    # AIä¼˜åŒ–é…ç½®
    st.markdown("### ğŸ¤– AIæ–‡æœ¬ä¼˜åŒ–")
    enable_ai_optimization = st.checkbox("å¯ç”¨AIæ–‡æœ¬ä¼˜åŒ–", value=False)
    
    if enable_ai_optimization:
        api_provider = st.selectbox(
            "é€‰æ‹©AIæœåŠ¡å•†",
            ["ç¡…åŸºæµåŠ¨", "ç«å±±å¤§æ¨¡å‹", "OpenAI", "Claude", "æœ¬åœ°æ¨¡å‹"],
            index=0,
            help="é€‰æ‹©ç”¨äºæ–‡æœ¬ä¼˜åŒ–çš„AIæœåŠ¡"
        )
        
        # æ ¹æ®é€‰æ‹©çš„æä¾›å•†æ˜¾ç¤ºç›¸åº”çš„é…ç½®
        if api_provider == "OpenAI":
            api_key = st.text_input("OpenAI API Key", type="password")
            api_model = st.selectbox("æ¨¡å‹", ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"])
            api_base_url = st.text_input("Base URL (å¯é€‰)", value="https://api.openai.com/v1")
            
        elif api_provider == "Claude":
            api_key = st.text_input("Claude API Key", type="password")
            api_model = st.selectbox("æ¨¡å‹", ["claude-3-haiku-20240307", "claude-3-sonnet-20240229", "claude-3-opus-20240229"])
            api_base_url = st.text_input("Base URL (å¯é€‰)", value="https://api.anthropic.com")
            
        elif api_provider == "ç¡…åŸºæµåŠ¨":
            api_key = st.text_input("ç¡…åŸºæµåŠ¨ API Key", type="password")
            api_model = st.selectbox("æ¨¡å‹", [
                "Qwen/Qwen2.5-7B-Instruct",
                "Qwen/Qwen2.5-14B-Instruct", 
                "Qwen/Qwen2.5-32B-Instruct",
                "THUDM/glm-4-9b-chat",
                "01-ai/Yi-1.5-9B-Chat-16K"
            ])
            api_base_url = st.text_input("Base URL", value="https://api.siliconflow.cn/v1")
            
        elif api_provider == "ç«å±±å¤§æ¨¡å‹":
            api_key = st.text_input("ç«å±±å¼•æ“ API Key", type="password")
            api_model = st.selectbox("æ¨¡å‹", [
                "doubao-lite-4k",
                "doubao-pro-4k", 
                "doubao-pro-32k",
                "doubao-pro-128k"
            ])
            api_base_url = st.text_input("Base URL", value="https://ark.cn-beijing.volces.com/api/v3")
            
        elif api_provider == "æœ¬åœ°æ¨¡å‹":
            api_key = ""
            api_model = st.text_input("æ¨¡å‹åç§°", value="qwen2.5:7b")
            api_base_url = st.text_input("æœ¬åœ°æ¨¡å‹URL", value="http://localhost:11434/v1")
    
    st.markdown("---")
    
    # ç³»ç»Ÿä¿¡æ¯
    st.markdown("### â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    
    if st.button("æ¸…ç†ä¸´æ—¶æ–‡ä»¶"):
        preprocessor.cleanup_temp_files()
        st.success("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼
    with st.expander("æ”¯æŒçš„éŸ³é¢‘æ ¼å¼"):
        st.write("â€¢ MP3 - æœ€å¸¸ç”¨æ ¼å¼")
        st.write("â€¢ WAV - æ— æŸæ ¼å¼")
        st.write("â€¢ M4A - Appleè®¾å¤‡å½•éŸ³")
        st.write("â€¢ FLAC - æ— æŸå‹ç¼©")
        st.write("â€¢ AAC - é«˜è´¨é‡å‹ç¼©")
        st.write("â€¢ OGG - å¼€æºæ ¼å¼")
        st.write("â€¢ WMA - Windowsæ ¼å¼")

# åˆå§‹åŒ–session state
if 'transcription_result' not in st.session_state:
    st.session_state.transcription_result = ""
    st.session_state.enhanced_result = ""
    st.session_state.transcription_result = ""
if 'progress' not in st.session_state:
    st.session_state.progress = 0
if 'is_transcribing' not in st.session_state:
    st.session_state.is_transcribing = False
if 'real_time_text' not in st.session_state:
    st.session_state.real_time_text = ""
if 'optimized_text' not in st.session_state:
    st.session_state.optimized_text = None

# åˆå§‹åŒ–æ–‡ä»¶é¢„å¤„ç†å™¨
preprocessor = FilePreprocessor()

# AIä¼˜åŒ–åŠŸèƒ½
async def optimize_text_with_ai(text, provider, optimization_type, custom_prompt="", api_config=None):
    """ä½¿ç”¨AIä¼˜åŒ–æ–‡æœ¬ï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œä¸­æ–‡è¯­è¨€çº¦æŸ"""
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            # æ„å»ºä¼˜åŒ–æç¤ºï¼Œå¼ºåˆ¶ä½¿ç”¨ä¸­æ–‡è¾“å‡º
            base_constraint = "è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒæ–‡æœ¬çš„ä¸­æ–‡ç‰¹è‰²å’Œè¡¨è¾¾ä¹ æƒ¯ã€‚"
            
            if optimization_type == "è¯­æ³•çº é”™":
                prompt = f"{base_constraint}è¯·çº æ­£ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ä¸­çš„è¯­æ³•é”™è¯¯ï¼Œä¿æŒåŸæ„ä¸å˜ï¼Œç¡®ä¿ç¬¦åˆä¸­æ–‡è¯­æ³•è§„èŒƒï¼š\n\n{text}"
            elif optimization_type == "æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–":
                prompt = f"{base_constraint}è¯·ä¸ºä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬æ·»åŠ æ­£ç¡®çš„ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼ˆå¦‚å¥å·ã€é€—å·ã€é—®å·ç­‰ï¼‰ï¼š\n\n{text}"
            elif optimization_type == "æ–‡æœ¬æ¶¦è‰²":
                prompt = f"{base_constraint}è¯·æ¶¦è‰²ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ï¼Œä½¿å…¶æ›´åŠ æµç•…è‡ªç„¶ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯ï¼š\n\n{text}"
            elif optimization_type == "æ ¼å¼æ•´ç†":
                prompt = f"{base_constraint}è¯·æ•´ç†ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬çš„æ ¼å¼ï¼Œä½¿å…¶æ›´åŠ è§„èŒƒï¼Œä¿æŒä¸­æ–‡æ’ç‰ˆç‰¹ç‚¹ï¼š\n\n{text}"
            elif optimization_type == "è‡ªå®šä¹‰æç¤º":
                prompt = f"{base_constraint}{custom_prompt}\n\n{text}"
            else:
                prompt = f"{base_constraint}è¯·ä¼˜åŒ–ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ï¼Œä½¿å…¶æ›´åŠ å‡†ç¡®å’Œæµç•…ï¼š\n\n{text}"
            
            # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            timeout = aiohttp.ClientTimeout(total=120)  # å¢åŠ åˆ°120ç§’
            
            # æ ¹æ®ä¸åŒæä¾›å•†æ„å»ºè¯·æ±‚
            if provider == "OpenAI":
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_config['api_key']}"
                }
                data = {
                    "model": api_config['model'],
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ï¼Œè¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 3000
                }
                endpoint = f"{api_config['base_url']}/chat/completions"
                
            elif provider == "ç¡…åŸºæµåŠ¨":
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_config['api_key']}"
                }
                data = {
                    "model": api_config['model'],
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ï¼Œè¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 3000
                }
                endpoint = f"{api_config['base_url']}/chat/completions"
                
            elif provider == "ç«å±±å¤§æ¨¡å‹":
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_config['api_key']}"
                }
                data = {
                    "model": api_config['model'],
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ï¼Œè¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 3000
                }
                endpoint = f"{api_config['base_url']}/chat/completions"
                
            elif provider == "Claude":
                headers = {
                    "Content-Type": "application/json",
                    "x-api-key": api_config['api_key'],
                    "anthropic-version": "2023-06-01"
                }
                data = {
                    "model": api_config['model'],
                    "max_tokens": 3000,
                    "system": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ï¼Œè¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ã€‚",
                    "messages": [{"role": "user", "content": prompt}]
                }
                endpoint = f"{api_config['base_url']}/v1/messages"
            
            # å‘é€å¼‚æ­¥è¯·æ±‚
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(endpoint, headers=headers, json=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        
                        if provider == "Claude":
                            return result["content"][0]["text"]
                        else:
                            return result["choices"][0]["message"]["content"]
                    else:
                        error_text = await response.text()
                        raise Exception(f"APIè¯·æ±‚å¤±è´¥ ({response.status}): {error_text}")
                        
        except asyncio.TimeoutError:
            retry_count += 1
            if retry_count >= max_retries:
                raise Exception(f"AIä¼˜åŒ–è¯·æ±‚è¶…æ—¶ï¼Œå·²é‡è¯•{max_retries}æ¬¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
            await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
            continue
        except Exception as e:
            retry_count += 1
            if retry_count >= max_retries:
                raise Exception(f"AIä¼˜åŒ–å¤±è´¥: {str(e)}")
            await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
            continue
    
    raise Exception("AIä¼˜åŒ–å¤±è´¥: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")

# å®æ—¶è½¬å½•åŠŸèƒ½
def real_time_transcribe_callback(text_chunk):
    """å®æ—¶è½¬å½•å›è°ƒå‡½æ•°"""
    if 'real_time_text' not in st.session_state:
        st.session_state.real_time_text = ""
    st.session_state.real_time_text += text_chunk + " "

# ä¼˜åŒ–çš„è½¬å½•å‡½æ•°
@st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
def get_audio_info(audio_path):
    """è·å–éŸ³é¢‘ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    audio = pydub.AudioSegment.from_file(audio_path)
    return {
        'duration': audio.duration_seconds,
        'channels': audio.channels,
        'frame_rate': audio.frame_rate,
        'sample_width': audio.sample_width
    }

def filter_chinese_content(text):
    """è¿‡æ»¤å¹¶ä¿ç•™ä¸­æ–‡å†…å®¹ï¼Œç§»é™¤éä¸­æ–‡å­—ç¬¦å’Œè¯æ±‡"""
    if not text:
        return ""
    
    import re
    
    # å®šä¹‰ä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼ˆåŒ…æ‹¬ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼‰
    chinese_pattern = r'[\u4e00-\u9fff\u3400-\u4dbf\uf900-\ufaff\u3000-\u303f\uff00-\uffef]'
    
    # å¸¸è§çš„éä¸­æ–‡è¯æ±‡æ¨¡å¼ï¼ˆæ—¥è¯­ã€éŸ©è¯­ç­‰ï¼‰
    non_chinese_patterns = [
        r'[\u3040-\u309f]',  # æ—¥è¯­å¹³å‡å
        r'[\u30a0-\u30ff]',  # æ—¥è¯­ç‰‡å‡å
        r'[\uac00-\ud7af]',  # éŸ©è¯­
        r'[\u0e00-\u0e7f]',  # æ³°è¯­
        r'[\u0900-\u097f]',  # æ¢µè¯­/å°åœ°è¯­
    ]
    
    # ç§»é™¤æ˜æ˜¾çš„éä¸­æ–‡å­—ç¬¦
    for pattern in non_chinese_patterns:
        text = re.sub(pattern, '', text)
    
    # åˆ†å‰²æ–‡æœ¬ä¸ºè¯æ±‡/çŸ­è¯­
    words = re.findall(r'[^\s\n]+', text)
    filtered_words = []
    
    for word in words:
        # æ£€æŸ¥è¯æ±‡æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        if re.search(chinese_pattern, word):
            # è¿›ä¸€æ­¥è¿‡æ»¤ï¼šå¦‚æœè¯æ±‡ä¸»è¦æ˜¯ä¸­æ–‡å­—ç¬¦ï¼Œåˆ™ä¿ç•™
            chinese_chars = len(re.findall(chinese_pattern, word))
            total_chars = len(word)
            
            # å¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”è¶…è¿‡50%ï¼Œåˆ™è®¤ä¸ºæ˜¯ä¸­æ–‡å†…å®¹
            if total_chars > 0 and chinese_chars / total_chars >= 0.5:
                filtered_words.append(word)
    
    # é‡æ–°ç»„åˆæ–‡æœ¬
    filtered_text = ''.join(filtered_words)
    
    # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœè¿‡æ»¤åçš„æ–‡æœ¬å¤ªçŸ­æˆ–æ²¡æœ‰ä¸­æ–‡ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    if len(filtered_text) < 2 or not re.search(chinese_pattern, filtered_text):
        return ""
    
    return filtered_text


def optimized_transcribe(model, audio_path, callback=None, progress_callback=None, enable_preprocessing=True, auto_split=True, chunk_duration=5):
    """ä¼˜åŒ–çš„è½¬å½•å‡½æ•°ï¼Œæ”¯æŒå®æ—¶å›è°ƒã€è¿›åº¦æ›´æ–°å’Œå¤§æ–‡ä»¶å¤„ç†"""
    try:
        # è·å–éŸ³é¢‘ä¿¡æ¯
        audio_info = get_audio_info(audio_path)
        audio_duration = audio_info['duration']
        
        logger.info(f"å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œæ—¶é•¿: {audio_duration:.1f}ç§’")
        
        if progress_callback:
            progress_callback(10, f"éŸ³é¢‘æ—¶é•¿: {audio_duration:.1f}ç§’")
        
        # éŸ³é¢‘é¢„å¤„ç†
        processed_audio_path = audio_path
        if enable_preprocessing:
            if progress_callback:
                progress_callback(15, "æ­£åœ¨ä¼˜åŒ–éŸ³é¢‘è´¨é‡...")
            
            try:
                processed_audio_path = preprocessor.optimize_audio_for_chinese(audio_path)
                logger.info("éŸ³é¢‘é¢„å¤„ç†å®Œæˆ")
            except Exception as e:
                logger.warning(f"éŸ³é¢‘é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶: {str(e)}")
                processed_audio_path = audio_path
        
        # æ ¹æ®éŸ³é¢‘é•¿åº¦é€‰æ‹©åˆé€‚çš„è½¬å½•æ–¹æ³•
        if audio_duration > SPEECH_LENGTH:
            if progress_callback:
                progress_callback(30, "å¼€å§‹é•¿éŸ³é¢‘å¤„ç†...")
            
            # é•¿éŸ³é¢‘å¤„ç† - ä½¿ç”¨transcribe_longè¿›è¡ŒVADåˆ†å‰²
            segments = transcribe_long(
                model=model, 
                audio=processed_audio_path,
                lang_sym="zh",  # å¼ºåˆ¶æŒ‡å®šä¸­æ–‡
                region_sym="CN"  # æŒ‡å®šä¸­å›½å¤§é™†
            )
            
            # åˆå¹¶æ‰€æœ‰åˆ†æ®µçš„è½¬å½•ç»“æœ
            transcription_text = ""
            for segment in segments:
                segment_text = segment.text if hasattr(segment, 'text') else str(segment)
                if segment_text:
                    transcription_text += segment_text + " "
            
            # ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–å’Œè¿‡æ»¤
            if transcription_text:
                transcription_text = filter_chinese_content(transcription_text)
                transcription_text = re.sub(r'\s+', '', transcription_text.strip())
            
            if callback:
                callback(transcription_text)
            
            if progress_callback:
                progress_callback(80, "è½¬å½•å®Œæˆ")
            
            return transcription_text
        else:
            if progress_callback:
                progress_callback(40, "å¼€å§‹çŸ­éŸ³é¢‘å¤„ç†...")
            
            # çŸ­éŸ³é¢‘ç›´æ¥å¤„ç† - ä½¿ç”¨transcribe
            result = transcribe(
                model=model, 
                audio=processed_audio_path,
                lang_sym="zh",  # å¼ºåˆ¶æŒ‡å®šä¸­æ–‡
                region_sym="CN"  # æŒ‡å®šä¸­å›½å¤§é™†
            )
            transcription_text = result.text if hasattr(result, 'text') else str(result)
            
            # ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–å’Œè¿‡æ»¤
            if transcription_text:
                transcription_text = filter_chinese_content(transcription_text)
                transcription_text = re.sub(r'\s+', '', transcription_text.strip())
            
            if callback:
                callback(transcription_text)
            
            if progress_callback:
                progress_callback(80, "è½¬å½•å®Œæˆ")
            
            return transcription_text
            
    except Exception as e:
        error_msg = f"è½¬å½•å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        if progress_callback:
            progress_callback(0, error_msg)
        raise Exception(error_msg)
    
    finally:
        # æ¸…ç†é¢„å¤„ç†çš„ä¸´æ—¶æ–‡ä»¶
        if enable_preprocessing and processed_audio_path != audio_path:
            try:
                os.unlink(processed_audio_path)
            except:
                pass

# ä¸€é”®å¯¼å‡ºåŠŸèƒ½
def create_export_package(transcription_text, model_name, language):
    """åˆ›å»ºå¯¼å‡ºåŒ…"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ç»Ÿè®¡ä¿¡æ¯
    char_count = len(transcription_text)
    word_count = len(transcription_text.split())
    line_count = transcription_text.count('\n') + 1
    
    # åˆ›å»ºä¸åŒæ ¼å¼çš„å†…å®¹
    export_data = {
        'txt': transcription_text,
        'json': {
            "timestamp": datetime.now().isoformat(),
            "model": model_name,
            "language": language,
            "transcription": transcription_text,
            "statistics": {
                "characters": char_count,
                "words": word_count,
                "lines": line_count
            }
        },
        'markdown': f"""# è¯­éŸ³è½¬å½•ç»“æœ

**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ¨¡å‹**: {model_name}
**è¯­è¨€**: {language}

## è½¬å½•å†…å®¹

{transcription_text}

## ç»Ÿè®¡ä¿¡æ¯

- å­—ç¬¦æ•°: {char_count}
- è¯æ•°: {word_count}
- è¡Œæ•°: {line_count}
""",
        'statistics': {
            'characters': char_count,
            'words': word_count,
            'lines': line_count
        }
    }
    
    return export_data, timestamp

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_transcription_model(model_name, device):
    model_dir = Path.home() / '.cache' / 'dolphin' / 'models'
    return load_model(model_name, model_dir=model_dir, device=device)

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
st.markdown('<div class="feature-card">', unsafe_allow_html=True)
st.subheader("ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ")

uploaded_file = st.file_uploader(
    'é€‰æ‹©éŸ³é¢‘æ–‡ä»¶', 
    type=['mp3', 'wav', 'ogg', 'm4a', 'flac'],
    help="æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼Œå»ºè®®ä½¿ç”¨WAVæˆ–MP3æ ¼å¼ä»¥è·å¾—æœ€ä½³æ•ˆæœ"
)

if uploaded_file is not None:
    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    file_details = {
        "æ–‡ä»¶å": uploaded_file.name,
        "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024 / 1024:.2f} MB",
        "æ–‡ä»¶ç±»å‹": uploaded_file.type
    }
    
    col1, col2 = st.columns(2)
    with col1:
        st.json(file_details)
    
    with col2:
        # éŸ³é¢‘é¢„è§ˆ
        st.audio(uploaded_file, format=uploaded_file.type)

# å®æ—¶éº¦å…‹é£å½•åˆ¶
st.subheader("ğŸ¤ å®æ—¶éº¦å…‹é£å½•åˆ¶")
audio = mic_recorder(
    start_prompt="å¼€å§‹å½•åˆ¶",
    stop_prompt="åœæ­¢å½•åˆ¶",
    just_once=False,
    use_container_width=True
)

if audio:
    # ä¿å­˜å½•åˆ¶çš„éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
        tmp_file.write(audio['bytes'])
        uploaded_file = type('UploadedFile', (), {'name': 'recorded_audio.wav', 'getvalue': lambda: audio['bytes'], 'type': 'audio/wav', 'size': len(audio['bytes'])})()
    st.audio(audio['bytes'], format='audio/wav')

st.markdown('</div>', unsafe_allow_html=True)

# è½¬å½•åŠŸèƒ½
if uploaded_file is not None:
    st.markdown('<div class="feature-card">', unsafe_allow_html=True)
    st.subheader("ğŸ¯ è¯­éŸ³è½¬å½•")
    st.subheader("ğŸŒ ç¿»è¯‘åŠŸèƒ½")
    if st.button("ç¿»è¯‘ä¸ºè‹±æ–‡"):
        if st.session_state.transcription_result:
            # å‡è®¾æˆ‘ä»¬æœ‰éŸ³é¢‘è·¯å¾„æˆ–æ–‡æœ¬ï¼Œè¿™é‡Œç®€å•ç¿»è¯‘æ–‡æœ¬
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": f"Translate to English: {st.session_state.transcription_result}"}]
            )
            translated_text = response.choices[0].message.content
            st.write("ç¿»è¯‘ç»“æœ:", translated_text)
        else:
            st.warning("è¯·å…ˆè¿›è¡Œè½¬å½•")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        transcribe_button = st.button(
            "ğŸš€ å¼€å§‹è½¬å½•", 
            type="primary",
            disabled=st.session_state.is_transcribing,
            use_container_width=True
        )
    
    with col2:
        if st.session_state.is_transcribing:
            st.button("â¹ï¸ åœæ­¢è½¬å½•", key="stop_transcribe", use_container_width=True)
    
    with col3:
        clear_button = st.button("ğŸ—‘ï¸ æ¸…é™¤ç»“æœ", use_container_width=True)
        if clear_button:
            st.session_state.transcription_result = ""
            st.session_state.progress = 0
            st.session_state.real_time_text = ""
    
    # å®æ—¶è¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
    if st.session_state.is_transcribing or st.session_state.progress > 0:
        st.markdown('<div class="progress-container">', unsafe_allow_html=True)
        st.subheader("ğŸ“Š è½¬å½•è¿›åº¦")
        
        progress_bar = st.progress(st.session_state.progress / 100)
        progress_text = st.empty()
        progress_text.text(f"è¿›åº¦: {st.session_state.progress}%")
        
        if st.session_state.is_transcribing:
            status_text = st.empty()
            status_text.info("ğŸ”„ æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶...")
        
        # å®æ—¶è½¬å½•æ–‡æœ¬æ˜¾ç¤º
        if st.session_state.real_time_text:
            st.markdown("**å®æ—¶è½¬å½•å†…å®¹ï¼š**")
            st.markdown(
                f'<div class="selectable-text">{st.session_state.real_time_text}</div>',
                unsafe_allow_html=True
            )
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # è½¬å½•å¤„ç†
    if transcribe_button and not st.session_state.is_transcribing:
        st.session_state.is_transcribing = True
        st.session_state.progress = 0
        st.session_state.real_time_text = ""
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¼˜åŒ–æ€§èƒ½
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            audio_path = tmp_file.name
        
        # åˆ›å»ºå®æ—¶æ˜¾ç¤ºå®¹å™¨
        real_time_container = st.empty()
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        
        try:
            # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰
            status_placeholder.info('ğŸ¤– æ­£åœ¨åŠ è½½æ¨¡å‹...')
            model = load_transcription_model(model_name, device)
            st.session_state.progress = 20
            progress_placeholder.progress(0.2)
            
            # åˆ†æéŸ³é¢‘ï¼ˆå¼‚æ­¥ä¼˜åŒ–ï¼‰
            status_placeholder.info('ğŸµ æ­£åœ¨åˆ†æéŸ³é¢‘æ–‡ä»¶...')
            audio_duration = pydub.AudioSegment.from_file(audio_path).duration_seconds
            st.session_state.progress = 40
            progress_placeholder.progress(0.4)
            
            # æ‰§è¡Œè½¬å½•ï¼ˆå®æ—¶æ˜¾ç¤ºï¼‰
            status_placeholder.info('ğŸ—£ï¸ æ­£åœ¨æ‰§è¡Œè¯­éŸ³è½¬å½•...')
            
            def update_real_time_display(text_chunk):
                st.session_state.real_time_text += text_chunk + " "
                real_time_container.markdown(
                    f'<div class="selectable-text">å®æ—¶è½¬å½•: {st.session_state.real_time_text}</div>',
                    unsafe_allow_html=True
                )
            
            def update_progress_display(progress, message):
                st.session_state.progress = min(progress, 95)
                progress_placeholder.progress(st.session_state.progress / 100)
                status_placeholder.info(f'ğŸ”„ {message}')
            
            transcription = optimized_transcribe(
                model=model, 
                audio_path=audio_path,
                callback=update_real_time_display,
                progress_callback=update_progress_display,
                enable_preprocessing=enable_preprocessing,
                auto_split=auto_split,
                chunk_duration=chunk_duration
            )
            
            # å¤„ç†ç»“æœ
            status_placeholder.info('ğŸ“ æ­£åœ¨å¤„ç†è½¬å½•ç»“æœ...')
            st.session_state.transcription_result = transcription
            st.session_state.progress = 100
            progress_placeholder.progress(1.0)
            status_placeholder.success("âœ… è½¬å½•å®Œæˆï¼")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(audio_path)
            
            # è‡ªåŠ¨æ˜¾ç¤ºä¸€é”®å¯¼å‡ºæŒ‰é’®
            export_data, timestamp = create_export_package(transcription, model_name, language)
            
            st.markdown("### ğŸ“¤ å¿«é€Ÿå¯¼å‡º")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.download_button(
                    label="ğŸ“„ å¯¼å‡ºTXT",
                    data=export_data['txt'],
                    file_name=f"transcription_{timestamp}.txt",
                    mime="text/plain",
                    type="primary",
                    use_container_width=True
                )
                # æ·»åŠ æ›´å¤šå¯¼å‡ºé€‰é¡¹ï¼Œå¦‚CSV
            with col2:
                st.download_button(
                    label="ğŸ“‹ å¯¼å‡ºJSON",
                    data=json.dumps(export_data['json'], ensure_ascii=False, indent=2),
                    file_name=f"transcription_{timestamp}.json",
                    mime="application/json",
                    type="primary",
                    use_container_width=True
                )
            with col3:
                st.download_button(
                    label="ğŸ“ å¯¼å‡ºMD",
                    data=export_data['markdown'],
                    file_name=f"transcription_{timestamp}.md",
                    mime="text/markdown",
                    type="primary",
                    use_container_width=True
                )
            
            # è‡ªåŠ¨åˆ·æ–°é¡µé¢æ˜¾ç¤ºç»“æœ
            time.sleep(1)
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")
            status_placeholder.error(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'audio_path' in locals():
                try:
                    os.unlink(audio_path)
                except:
                    pass
        finally:
            st.session_state.is_transcribing = False
    
    st.markdown('</div>', unsafe_allow_html=True)

# ç»“æœæ˜¾ç¤ºå’Œæ“ä½œ
if st.session_state.transcription_result:
    st.markdown('<div class="feature-card">', unsafe_allow_html=True)
    st.subheader("ğŸ“„ è½¬å½•ç»“æœ")
    
    # å¯é€‰æ‹©çš„æ–‡æœ¬æ˜¾ç¤º
    st.markdown(
        f'<div class="selectable-text">{st.session_state.transcription_result}</div>',
        unsafe_allow_html=True
    )
    
    # æ–‡æœ¬ç»Ÿè®¡
    word_count = len(st.session_state.transcription_result.split())
    char_count = len(st.session_state.transcription_result)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å­—ç¬¦æ•°", char_count)
    with col2:
        st.metric("è¯æ•°", word_count)
    with col3:
        st.metric("è¡Œæ•°", st.session_state.transcription_result.count('\n') + 1)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # å¯¼å‡ºåŠŸèƒ½
    st.markdown('<div class="feature-card">', unsafe_allow_html=True)
    st.subheader("ğŸ’¾ å¯¼å‡ºé€‰é¡¹")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # å¯¼å‡ºä¸ºTXT
        txt_data = st.session_state.transcription_result
        st.download_button(
            label="ğŸ“„ å¯¼å‡ºTXT",
            data=txt_data,
            file_name=f"transcription_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
    
    with col2:
        # å¯¼å‡ºä¸ºJSON
        json_data = {
            "timestamp": datetime.now().isoformat(),
            "model": model_name,
            "language": language,
            "transcription": st.session_state.transcription_result,
            "statistics": {
                "characters": char_count,
                "words": word_count,
                "lines": st.session_state.transcription_result.count('\n') + 1
            }
        }
        st.download_button(
            label="ğŸ“‹ å¯¼å‡ºJSON",
            data=json.dumps(json_data, ensure_ascii=False, indent=2),
            file_name=f"transcription_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    with col3:
        # å¯¼å‡ºä¸ºMarkdown
        newline_count = st.session_state.transcription_result.count('\n') + 1
        md_data = f"""# è¯­éŸ³è½¬å½•ç»“æœ

**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ¨¡å‹**: {model_name}
**è¯­è¨€**: {language}

## è½¬å½•å†…å®¹

{st.session_state.transcription_result}

## ç»Ÿè®¡ä¿¡æ¯

- å­—ç¬¦æ•°: {char_count}
- è¯æ•°: {word_count}
- è¡Œæ•°: {newline_count}
"""
        st.download_button(
            label="ğŸ“ å¯¼å‡ºMarkdown",
            data=md_data,
            file_name=f"transcription_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
    
    with col4:
        # å¤åˆ¶åˆ°å‰ªè´´æ¿
        if st.button("ğŸ“‹ å¤åˆ¶æ–‡æœ¬"):
            st.code(st.session_state.transcription_result)
            st.success("æ–‡æœ¬å·²æ˜¾ç¤ºï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # AIæ–‡æœ¬ä¼˜åŒ–
    if st.session_state.get('transcription_result'):
        st.header("ğŸ¤– AIæ–‡æœ¬ä¼˜åŒ–")
        
        # AIæœåŠ¡å•†é€‰æ‹©
        ai_provider = st.selectbox(
            "é€‰æ‹©AIæœåŠ¡å•†",
            ["OpenAI", "ç¡…åŸºæµåŠ¨", "ç«å±±å¤§æ¨¡å‹", "Claude"],
            key="ai_provider_select"
        )
        
        # æ ¹æ®é€‰æ‹©çš„æœåŠ¡å•†æ˜¾ç¤ºé…ç½®
        if ai_provider == "OpenAI":
            openai_api_key = st.text_input("OpenAI API Key", type="password", key="openai_key_input")
            openai_base_url = st.text_input("Base URL (å¯é€‰)", value="https://api.openai.com/v1", key="openai_base_url")
            openai_model = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"], key="openai_model_select")
            
        elif ai_provider == "ç¡…åŸºæµåŠ¨":
            siliconflow_api_key = st.text_input("ç¡…åŸºæµåŠ¨ API Key", type="password", key="siliconflow_key_input")
            siliconflow_base_url = st.text_input("Base URL", value="https://api.siliconflow.cn/v1", key="siliconflow_base_url")
            siliconflow_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹", 
                ["Qwen/Qwen2.5-72B-Instruct", "deepseek-ai/DeepSeek-V2.5", "meta-llama/Meta-Llama-3.1-70B-Instruct"],
                key="siliconflow_model_select"
            )
            
        elif ai_provider == "ç«å±±å¤§æ¨¡å‹":
            volcano_api_key = st.text_input("ç«å±±å¤§æ¨¡å‹ API Key", type="password", key="volcano_key_input")
            volcano_base_url = st.text_input("Base URL", value="https://ark.cn-beijing.volces.com/api/v3", key="volcano_base_url")
            volcano_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹", 
                ["doubao-pro-4k", "doubao-lite-4k", "doubao-pro-32k"],
                key="volcano_model_select"
            )
            
        elif ai_provider == "Claude":
            claude_api_key = st.text_input("Claude API Key", type="password", key="claude_key_input")
            claude_base_url = st.text_input("Base URL", value="https://api.anthropic.com", key="claude_base_url")
            claude_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹", 
                ["claude-3-haiku-20240307", "claude-3-sonnet-20240229", "claude-3-opus-20240229"],
                key="claude_model_select"
            )
        
        # ä¼˜åŒ–ç±»å‹é€‰æ‹©
        optimization_type = st.selectbox(
            "é€‰æ‹©ä¼˜åŒ–ç±»å‹",
            ["è¯­æ³•çº é”™", "æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–", "æ–‡æœ¬æ¶¦è‰²", "æ ¼å¼æ•´ç†", "è‡ªå®šä¹‰æç¤º"],
            key="optimization_type_select"
        )
        
        # è‡ªå®šä¹‰æç¤º
        custom_prompt = ""
        if optimization_type == "è‡ªå®šä¹‰æç¤º":
            custom_prompt = st.text_area(
                "è¾“å…¥è‡ªå®šä¹‰ä¼˜åŒ–æç¤º",
                placeholder="è¯·è¾“å…¥æ‚¨å¸Œæœ›AIå¦‚ä½•ä¼˜åŒ–æ–‡æœ¬çš„å…·ä½“è¦æ±‚...",
                key="custom_prompt_input"
            )
        
        # ä¼˜åŒ–æ§åˆ¶æŒ‰é’®
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸš€ å¼€å§‹ä¼˜åŒ–", type="primary", use_container_width=True):
                # æ£€æŸ¥APIå¯†é’¥
                api_key_valid = False
                if ai_provider == "OpenAI" and openai_api_key:
                    api_key_valid = True
                elif ai_provider == "ç¡…åŸºæµåŠ¨" and siliconflow_api_key:
                    api_key_valid = True
                elif ai_provider == "ç«å±±å¤§æ¨¡å‹" and volcano_api_key:
                    api_key_valid = True
                elif ai_provider == "Claude" and claude_api_key:
                    api_key_valid = True
                
                if not api_key_valid:
                    st.error(f"è¯·è¾“å…¥{ai_provider}çš„API Key")
                elif optimization_type == "è‡ªå®šä¹‰æç¤º" and not custom_prompt.strip():
                    st.error("è¯·è¾“å…¥è‡ªå®šä¹‰ä¼˜åŒ–æç¤º")
                else:
                    # æ‰§è¡ŒAIä¼˜åŒ–
                    with st.spinner(f"æ­£åœ¨ä½¿ç”¨{ai_provider}ä¼˜åŒ–æ–‡æœ¬..."):
                        try:
                            # å‡†å¤‡APIå‚æ•°
                            if ai_provider == "OpenAI":
                                api_config = {
                                    "api_key": openai_api_key,
                                    "base_url": openai_base_url,
                                    "model": openai_model
                                }
                            elif ai_provider == "ç¡…åŸºæµåŠ¨":
                                api_config = {
                                    "api_key": siliconflow_api_key,
                                    "base_url": siliconflow_base_url,
                                    "model": siliconflow_model
                                }
                            elif ai_provider == "ç«å±±å¤§æ¨¡å‹":
                                api_config = {
                                    "api_key": volcano_api_key,
                                    "base_url": volcano_base_url,
                                    "model": volcano_model
                                }
                            elif ai_provider == "Claude":
                                api_config = {
                                    "api_key": claude_api_key,
                                    "base_url": claude_base_url,
                                    "model": claude_model
                                }
                            
                            # å¼‚æ­¥æ‰§è¡Œä¼˜åŒ–
                            optimized_result = asyncio.run(
                                optimize_text_with_ai(
                                    text=st.session_state.transcription_result,
                                    provider=ai_provider,
                                    optimization_type=optimization_type,
                                    custom_prompt=custom_prompt,
                                    api_config=api_config
                                )
                            )
                            
                            st.session_state.optimized_text = optimized_result
                            st.success(f"âœ… ä½¿ç”¨{ai_provider}ä¼˜åŒ–å®Œæˆï¼")
                            
                        except Exception as e:
                            st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}")
        
        with col2:
            if st.button("ğŸ”„ é‡ç½®ä¼˜åŒ–", use_container_width=True):
                st.session_state.optimized_text = None
                st.rerun()
        
        # æ˜¾ç¤ºä¼˜åŒ–ç»“æœ
        if st.session_state.get('optimized_text'):
            st.subheader("ğŸ“Š ä¼˜åŒ–ç»“æœå¯¹æ¯”")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**åŸå§‹æ–‡æœ¬**")
                st.text_area(
                    "åŸå§‹è½¬å½•ç»“æœ",
                    value=st.session_state.transcription_result,
                    height=300,
                    key="original_text_display"
                )
                
                # åŸå§‹æ–‡æœ¬ç»Ÿè®¡
                original_chars = len(st.session_state.transcription_result)
                original_words = len(st.session_state.transcription_result.split())
                st.caption(f"å­—ç¬¦æ•°: {original_chars} | è¯æ•°: {original_words}")
            
            with col2:
                st.markdown("**ä¼˜åŒ–åæ–‡æœ¬**")
                st.text_area(
                    "AIä¼˜åŒ–ç»“æœ",
                    value=st.session_state.optimized_text,
                    height=300,
                    key="optimized_text_display"
                )
                
                # ä¼˜åŒ–æ–‡æœ¬ç»Ÿè®¡
                optimized_chars = len(st.session_state.optimized_text)
                optimized_words = len(st.session_state.optimized_text.split())
                st.caption(f"å­—ç¬¦æ•°: {optimized_chars} | è¯æ•°: {optimized_words}")
            
            # æ›¿æ¢åŸæ–‡é€‰é¡¹
            if st.button("ğŸ”„ ç”¨ä¼˜åŒ–ç»“æœæ›¿æ¢åŸæ–‡", use_container_width=True):
                st.session_state.transcription_result = st.session_state.optimized_text
                st.session_state.optimized_text = None
                st.success("âœ… å·²æ›¿æ¢åŸæ–‡ï¼")
                st.rerun()
            
            # ä¼˜åŒ–ç»“æœå¯¼å‡º
            st.subheader("ğŸ“¤ å¯¼å‡ºä¼˜åŒ–ç»“æœ")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                # TXTå¯¼å‡º
                st.download_button(
                    label="ğŸ“„ å¯¼å‡ºTXT",
                    data=st.session_state.optimized_text,
                    file_name=f"optimized_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            with col2:
                # JSONå¯¼å‡º
                optimized_json = {
                    "original_text": st.session_state.transcription_result,
                    "optimized_text": st.session_state.optimized_text,
                    "ai_provider": ai_provider,
                    "optimization_type": optimization_type,
                    "timestamp": datetime.now().isoformat(),
                    "statistics": {
                        "original": {
                            "characters": len(st.session_state.transcription_result),
                            "words": len(st.session_state.transcription_result.split())
                        },
                        "optimized": {
                            "characters": len(st.session_state.optimized_text),
                            "words": len(st.session_state.optimized_text.split())
                        }
                    }
                }
                st.download_button(
                    label="ğŸ“Š å¯¼å‡ºJSON",
                    data=json.dumps(optimized_json, ensure_ascii=False, indent=2),
                    file_name=f"optimized_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )
            
            with col3:
                # Markdownå¯¼å‡º
                optimized_markdown = f"""# AIæ–‡æœ¬ä¼˜åŒ–ç»“æœ

## ä¼˜åŒ–ä¿¡æ¯
- **AIæœåŠ¡å•†**: {ai_provider}
- **ä¼˜åŒ–ç±»å‹**: {optimization_type}
- **æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## åŸå§‹æ–‡æœ¬
{st.session_state.transcription_result}

## ä¼˜åŒ–åæ–‡æœ¬
{st.session_state.optimized_text}

## ç»Ÿè®¡å¯¹æ¯”
- **åŸå§‹**: {len(st.session_state.transcription_result)}å­—ç¬¦, {len(st.session_state.transcription_result.split())}è¯
- **ä¼˜åŒ–å**: {len(st.session_state.optimized_text)}å­—ç¬¦, {len(st.session_state.optimized_text.split())}è¯
"""
                st.download_button(
                    label="ğŸ“ å¯¼å‡ºMD",
                    data=optimized_markdown,
                    file_name=f"optimized_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown",
                    use_container_width=True
                )
            
            with col4:
                # å¯¹æ¯”æŠ¥å‘Šå¯¼å‡º
                comparison_report = f"""# æ–‡æœ¬ä¼˜åŒ–å¯¹æ¯”æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **ä¼˜åŒ–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **AIæœåŠ¡å•†**: {ai_provider}
- **ä¼˜åŒ–ç±»å‹**: {optimization_type}

## æ–‡æœ¬ç»Ÿè®¡å¯¹æ¯”
| é¡¹ç›® | åŸå§‹æ–‡æœ¬ | ä¼˜åŒ–åæ–‡æœ¬ | å˜åŒ– |
|------|----------|------------|------|
| å­—ç¬¦æ•° | {len(st.session_state.transcription_result)} | {len(st.session_state.optimized_text)} | {len(st.session_state.optimized_text) - len(st.session_state.transcription_result):+d} |
| è¯æ•° | {len(st.session_state.transcription_result.split())} | {len(st.session_state.optimized_text.split())} | {len(st.session_state.optimized_text.split()) - len(st.session_state.transcription_result.split()):+d} |

## è¯¦ç»†å†…å®¹

### åŸå§‹æ–‡æœ¬
```
{st.session_state.transcription_result}
```

### ä¼˜åŒ–åæ–‡æœ¬
```
{st.session_state.optimized_text}
```
"""
                st.download_button(
                    label="ğŸ“‹ å¯¹æ¯”æŠ¥å‘Š",
                    data=comparison_report,
                    file_name=f"comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown",
                    use_container_width=True
                )

# é¡µè„šä¿¡æ¯
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    <p>ğŸ¬ Dolphin Audio Transcription | åŸºäºæ·±åº¦å­¦ä¹ çš„é«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«</p>
    <p>æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ | å®æ—¶è¿›åº¦è·Ÿè¸ª | AIæ™ºèƒ½ä¼˜åŒ–</p>
</div>
""", unsafe_allow_html=True)